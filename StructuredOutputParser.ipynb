{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-core langchain-huggingface python-dotenv"
      ],
      "metadata": {
        "id": "T_33j1xYawJr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q huggingface_hub\n"
      ],
      "metadata": {
        "id": "OjCnzxYCazsP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\"\n"
      ],
      "metadata": {
        "id": "6RoUug3bbNNN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYffvdvkah3l",
        "outputId": "6aa26118-94dc-4e3e-b1a6-f152fee62c6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fact_1': 'AI engineers with a specialization in Natural Language Processing (NLP) can command salaries exceeding ₹50 lakh per annum.', 'fact_2': 'The demand for skilled AI engineers is rapidly growing, significantly contributing to higher compensation packages in the sector.', 'fact_3': 'Compensation for AI engineers may vary based on factors such as experience, location, and company size, with specialization, skills and proven track record playing a decisive role.'}\n"
          ]
        }
      ],
      "source": [
        "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
        "from dotenv import load_dotenv\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
        "import os\n",
        "\n",
        "# ✅ Set token manually if .env not working\n",
        "# (skip if already set)\n",
        "# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"hf_xxxxx\"\n",
        "\n",
        "# Load env (optional if .env present)\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize the Hugging Face model endpoint\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"google/gemma-2-2b-it\",\n",
        "    task=\"text-generation\",\n",
        "    huggingfacehub_api_token=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")  # ✅ explicitly passed\n",
        ")\n",
        "\n",
        "# Wrap it in a Chat interface\n",
        "model = ChatHuggingFace(llm=llm)\n",
        "\n",
        "# Define schema for structured output\n",
        "schema = [\n",
        "    ResponseSchema(name='fact_1', description='Fact 1 about the topic'),\n",
        "    ResponseSchema(name='fact_2', description='Fact 2 about the topic'),\n",
        "    ResponseSchema(name='fact_3', description='Fact 3 about the topic'),\n",
        "]\n",
        "\n",
        "parser = StructuredOutputParser.from_response_schemas(schema)\n",
        "\n",
        "# Create the prompt\n",
        "template = PromptTemplate(\n",
        "    template='Give 3 facts about {topic} \\n{format_instruction}',\n",
        "    input_variables=['topic'],\n",
        "    partial_variables={'format_instruction': parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "# Build and execute the chain\n",
        "chain = template | model | parser\n",
        "\n",
        "result = chain.invoke({'topic': 'ai engineer 50lpa'})\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9nWFifOeaj06"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}